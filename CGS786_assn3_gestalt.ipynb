{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestalt Principles and CNNs\n",
    "- Submitted by Sankalp Mittal (220963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part a\n",
    "In this part we are required to repriduce the study design using inception v4 networks instead of inception v3 networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV4 Implementation\n",
    "I am using the following [github](https://github.com/kentsommer/keras-inceptionV4/tree/master) repository for the code for InceptionV4 model implementation as it was not available in the keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 17:47:59.968964: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-02 17:48:00.005907: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-02 17:48:00.229182: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-02 17:48:00.327003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743596280.496741    3179 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743596280.538560    3179 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743596280.814681    3179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743596280.814766    3179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743596280.814768    3179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743596280.814770    3179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-02 17:48:00.844073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "# from tensorflow.keras.models import Model\n",
    "import inception_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inceptionV4(num_classes=1001, dropout_prob=0.2, weights='imagenet', include_top=True):\n",
    "    try:\n",
    "        return inception_v4.create_model(num_classes, dropout_prob, weights, include_top)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return inception_v4.create_model(num_classes, dropout_prob, weights, include_top)\n",
    "        except ValueError:\n",
    "            return inception_v4.create_model(num_classes, dropout_prob, weights, include_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a check to see model is being built without any problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_inceptionV4(num_classes=1001, dropout_prob=0.2, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "We generate the datasets using the `createImage` file using the following commands in the file directly\n",
    "```\n",
    "generate_global_symmetric_data()\n",
    "# generate_local_symmetric_data()\n",
    "# generate_count_object_data()\n",
    "# generate_count_type_data()\n",
    "```\n",
    "We only generate global symmetry data as only that is asked in the question, even that comes out to be approximately __8GB__ in size just for _ds1_ and _ds2_ after which my system started killing the process, so I generated the datasets sequentially so that the run goes smoothly.\n",
    "\n",
    "As even that was not working I just generated a dataset of size 10% of what was mentioned in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b\n",
    "In this part we try to reproduce the results produced for InceptionV3 models with InceptionV4 for the case of detecting symmetry in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same helper functions for training as in the case of InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_incep3\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Run 1\n",
    "This will run on ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_3179/1192969502.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  ds = \"data\\symmetry_global\\ds1\"\n"
     ]
    }
   ],
   "source": [
    "ds = \"data\\symmetry_global\\ds1\"\n",
    "resume_model = None\n",
    "im_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx.shape:  (800, 299, 299)\n",
      "vx.shape:  (800, 299, 299)\n",
      "About to build model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1743596305.533875    3179 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1743596305.537005    3179 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/sankalp/CGS786_assn3/final_implementation/inception_v4.py:279: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n",
      "/home/sankalp/.local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nb_epoch2 = 10\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "# load data\n",
    "tx, ty = train_incep3.read_dataset(ds+'/train.data')\n",
    "vx, vy = train_incep3.read_dataset(ds+'/valid.data')\n",
    "\n",
    "nTrainSample = len(ty)\n",
    "\n",
    "tx = train_incep3.preprocessing_img(tx)\n",
    "vx = train_incep3.preprocessing_img(vx)\n",
    "print(\"tx.shape: \", tx.shape)\n",
    "# print(\"ty.shape: \", ty.shape)\n",
    "print(\"vx.shape: \", vx.shape)\n",
    "# print(\"vy.shape: \", vy.shape)\n",
    "\n",
    "tx = np.asarray(tx)[:, np.newaxis, :, :]\n",
    "vx = np.asarray(vx)[:, np.newaxis, :, :]\n",
    "tx = np.repeat(tx, 3, axis=1)\n",
    "vx = np.repeat(vx, 3, axis=1)\n",
    "\n",
    "    \n",
    "ty = train_incep3.to_categorical(ty, 2)\n",
    "vy = train_incep3.to_categorical(vy, 2)\n",
    "\n",
    "## build model\n",
    "print(\"About to build model\")\n",
    "model = build_inceptionV4(num_classes=2)\n",
    "\n",
    "datagen = train_incep3.ImageDataGenerator(\n",
    "    preprocessing_function=train_incep3.add_random_noise if im_noise else None,\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.02,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.02,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images\n",
    "    \n",
    "\n",
    "if resume_model is not None:\n",
    "    print('Resume model: ', resume_model)\n",
    "    model.load_weights(resume_model)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "filepath2=\"models/\"+ds+\"_incep3-{epoch:02d}-{val_acc:.3f}.weights.h5\"\n",
    "checkpoint2 = train_incep3.callbacks.ModelCheckpoint(filepath2, monitor='val_acc', verbose=0, save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "early_stopper   = train_incep3.EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=40)\n",
    "\n",
    "callbacks_list2 = [early_stopper, checkpoint2]\n",
    "\n",
    "# we train our model \n",
    "model.fit(datagen.flow(tx, ty, batch_size=40, shuffle=True),\n",
    "                    steps_per_epoch=nTrainSample//40,\n",
    "                    epochs=nb_epoch2,\n",
    "                    validation_data=(vx, vy),\n",
    "                    callbacks=callbacks_list2)\n",
    "\n",
    "        \n",
    "# serialize last weights to HDF5\n",
    "model.save_weights(ds+\"_incep3-%d.weights.h5\"%(nb_epoch2))\n",
    "\n",
    "print(\"Saved last weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
